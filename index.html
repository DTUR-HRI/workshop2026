<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Workshop on Designing Transparent and Understandable Robots (D-TUR)</title>
  <link rel="stylesheet" href="style.css" />
</head>

<body>
  <header>
    <h1>Workshop on Designing Transparent and Understandable Robots (D-TUR)</h1>
    <h3>HRI ’26, March 16–19, 2026, Edinburgh, Scotland, UK</h3>
  </header>

  <main>
    <section id="about">
      <h2>About the Workshop</h2>
      <p>
        In order for robots to act as an empowering tool in today’s society, it is necessary for users to understand what those robots can and cannot do. This can happen through the design of the robot, through external information such as signs and manuals, or through the interaction itself. With this workshop, we aim to provide a platform for participants who approach robot transparency from different angles to share and discuss their experiences.
      </p>
      <p>
        In this workshop, participants will have the opportunity to deepen their knowledge of transparent and understandable robot interactions through two keynotes and paper presentations. In the second part of the workshop, the diverse backgrounds of participants will be brought together in interactive exercises that aim to address questions about topics such as how transparency can be used to reduce inequalities and empower society and other open problems in the field. The guided break-out sessions aim at giving participants the chance to reflect on the keynotes, paper presentations and their own work and to share those reflections with participants with other perspectives.
      </p>

      <h2>Background</h2>
      <p>
        In order for human-robot interaction (HRI) to empower society, people must know how to use and safely work around robots that they may interact with. As robots are deployed in our everyday lives, they will encounter novice users who do not have prior experience with robots. Currently, not everyone has easy access to robots, creating an inequality in familiarity with this technology. As they are not familiar with robots, the robot’s capabilities and behaviors might not be easy to understand, potentially leading to unsafe or inefficient interactions.
      </p>
      <p>
        Various approaches have been used to make robots and their behavior understandable. Robots can be designed with affordances that establish expectations for their purpose and functionality. It is also possible to increase the legibility of robot behaviors, such as movements, to enable the human to infer the robot’s intents and goals. Other options include increasing the transparency of the system by providing the reasoning behind decisions or by increasing the legibility of robot actions, making the goal predictable, and by providing verbal explanations. A robot can also explain its behavior and capabilities through social clues, like speech, images, movement, or text. Transparency is not limited to the robot’s capabilities but also can include what it cannot do and can use various modalities such as behaviors and screens. Failure explanations help users understand the limits of robots so that they can learn how to prevent, diagnose, or recover from these failures.
      </p>
      <p>
        Not only are there multiple approaches to consider when designing or integrating robots to work alongside people to promote an accurate understanding of robot behaviors, but there are also no standard methods to evaluate understanding and explanations in HRI. An effort has been made to bridge this gap by proposing a scale for measuring transparency. With our workshop, we aim to provide people with a platform to share their experiences and challenges with making systems transparent and understandable. Moreover, we aim to raise awareness of why it is important for robots to be understood if we want to use them to empower society.
      </p>
      <p>
        The goal of this workshop is to connect people working on different aspects of making robots understandable. Additionally, it aims to provide the broader HRI audience with information on how they can make their robots more understandable to users and empower everyone to use them more easily.
      </p>
    </section>

    <section id="cfp">
      <h2>Call for Papers</h2>
      <h3>Target Audience and Workshop Themes</h3>
      <p>
        We aim to bring together HRI researchers from different backgrounds to discuss open questions and novel work or ideas geared towards designing transparent and understandable robots. This includes a variety of topics, such as but not limited to:
      </p>
      <ul>
        <li>Designing robots with affordances</li>
        <li>Designing legible robot behaviors</li>
        <li>Transparency through XAI or mechanistic interpretability</li>
        <li>Understanding robot failures</li>
        <li>Understanding robot intent</li>
        <li>Understanding robot capability</li>
        <li>Explanations in HRI</li>
        <li>Metrics & evaluation methods for measuring understanding</li>
        <li>Co-designing understandable robots with users</li>
        <li>(Dis-)Advantages of making robots understandable</li>
        <li>Personalization to improve understanding</li>
        <li>Adapting the level of transparency based on context</li>
      </ul>
    </section>

    <section id="schedule">
      <h2>Workshop Format and Tentative Schedule</h2>
      <p>
        The half-day workshop will take place as a hybrid event. In-person attendance will be encouraged; we will offer a hybrid option to increase accessibility and reach. The workshop will consist of two keynotes, presentations for accepted papers, and interactive break-out sessions.
      </p>
      <h3>Tentative Schedule</h3>
      <ul>
        <li>09:00 - 09:05 Welcome and introduction to the workshop</li>
        <li>09:05 - 09:45 Keynote 1 and Q&A</li>
        <li>09:45 - 10:30 Paper presentations</li>
        <li>10:30 - 10:50 Coffee break and networking</li>
        <li>10:50 - 11:30 Keynote 2 and Q&A</li>
        <li>11:30 - 12:15 Interactive break-out sessions</li>
        <li>12:15 - 12:45 Discussing the break-out session results</li>
        <li>12:45 - 13:00 Concluding remarks</li>
      </ul>
      <p>
        Confirmed keynote speakers include <strong>Henny Admoni</strong> (Carnegie Mellon University) and <strong>Alessandra Rossi</strong> (University of Naples “Federico II”).
      </p>
    </section>

    <section id="organizers">
      <h2>Organizers</h2>

      <div class="organizer">
        <!-- <img src="images/placeholder.jpg" alt="Merle Reimann"> -->
        <h3>Merle Reimann</h3>
        <p>KTH Royal Institute of Technology, Sweden</p>
        <p>Postdoctoral Researcher in the Robotics, Perception and Learning division. Researches how robots can communicate their capabilities to users through interaction.</p>
      </div>

      <div class="organizer">
        <!-- <img src="images/placeholder.jpg" alt="Gregory LeMasurier"> -->
        <h3>Gregory LeMasurier</h3>
        <p>University of Massachusetts Lowell, USA</p>
        <p>Ph.D. student focusing on enabling novices to understand robot failures and non-verbal robot intent communication.</p>
      </div>

      <div class="organizer">
        <!-- <img src="images/placeholder.jpg" alt="Wenxi Wu"> -->
        <h3>Wenxi Wu</h3>
        <p>King’s College London / Imperial College London, UK</p>
        <p>Ph.D. student at the Centre for Doctoral Training in Safe & Trusted AI, researching explanations for motion planning failures.</p>
      </div>

      <div class="organizer">
        <!-- <img src="images/placeholder.jpg" alt="Lennart Wachowiak"> -->
        <h3>Lennart Wachowiak</h3>
        <p>King’s College London / Imperial College London, UK</p>
        <p>Ph.D. student focused on enabling robots to proactively explain their actions and select relevant information for users.</p>
      </div>

      <div class="organizer">
        <!-- <img src="images/placeholder.jpg" alt="Parag Khanna"> -->
        <h3>Parag Khanna</h3>
        <p>KTH Royal Institute of Technology, Sweden</p>
        <p>Postdoctoral Researcher in the Robotics, Perception and Learning division. Works on human-robot collaboration, failure explanations, and adaptive transparency.</p>
      </div>

      <div class="organizer">
        <!-- <img src="images/placeholder.jpg" alt="Christian Smith"> -->
        <h3>Christian Smith</h3>
        <p>KTH Royal Institute of Technology, Sweden</p>
        <p>Associate Professor researching physical human-robot interaction and robot learning in collaborative tasks.</p>
      </div>

      <div class="organizer">
        <!-- <img src="images/placeholder.jpg" alt="Iolanda Leite"> -->
        <h3>Iolanda Leite</h3>
        <p>KTH Royal Institute of Technology, Sweden</p>
        <p>Associate Professor focusing on human-centered AI and long-term human-robot interaction.</p>
      </div>

      <div class="organizer">
        <!-- <img src="images/placeholder.jpg" alt="Martim Brandao"> -->
        <h3>Martim Brandao</h3>
        <p>King’s College London, UK</p>
        <p>Lecturer (Assistant Professor) researching robot perception, planning, and interaction in uncertain environments.</p>
      </div>

      <div class="organizer">
        <!-- <img src="images/placeholder.jpg" alt="Gerard Canal"> -->
        <h3>Gerard Canal</h3>
        <p>King’s College London, UK</p>
        <p>Lecturer in autonomous systems studying explainable robotics, goal reasoning, and planning in assistive robot systems.</p>
      </div>
    </section>
  </main>

  <footer>
    <p>&copy; 2025 D-TUR Workshop | HRI ’26, Edinburgh, Scotland</p>
  </footer>
</body>
</html>
